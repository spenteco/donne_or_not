{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swiped from Nick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "{'syllabic': 1, 'stress': 0, 'long': 0, 'consonantal': 0, 'sonorant': 1, 'continuant': 1, 'delayed release': 0, 'approximant': 1, 'tap': 0, 'trill': 0, 'nasal': 0, 'voice': 1, 'spread gl': 0, 'constr gl': 0, 'LABIAL': 1, 'round': 1, 'labiodental': 0, 'CORONAL': 0, 'anterior': 0, 'distributed': 0, 'strident': 0, 'lateral': 0, 'DORSAL': 1, 'high': 0, 'low': 1, 'front': 0, 'back': 1, 'tense': 0, 'j-offglide': 0, 'w-offglide': 0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syllabic</th>\n",
       "      <th>stress</th>\n",
       "      <th>long</th>\n",
       "      <th>consonantal</th>\n",
       "      <th>sonorant</th>\n",
       "      <th>continuant</th>\n",
       "      <th>delayed release</th>\n",
       "      <th>approximant</th>\n",
       "      <th>tap</th>\n",
       "      <th>trill</th>\n",
       "      <th>...</th>\n",
       "      <th>strident</th>\n",
       "      <th>lateral</th>\n",
       "      <th>DORSAL</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>front</th>\n",
       "      <th>back</th>\n",
       "      <th>tense</th>\n",
       "      <th>j-offglide</th>\n",
       "      <th>w-offglide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ɒ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ɑ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ɶ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eɪ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ɔɪ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oʊ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aʊ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ɹ̩</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    syllabic  stress  long  consonantal  sonorant  continuant  \\\n",
       "ɒ          1       0     0            0         1           1   \n",
       "ɑ          1       0     0            0         1           1   \n",
       "ɶ          1       0     0            0         1           1   \n",
       "a          1       0     0            0         1           1   \n",
       "æ          1       0     0            0         1           1   \n",
       "..       ...     ...   ...          ...       ...         ...   \n",
       "eɪ         1       0     0            0         1           1   \n",
       "ɔɪ         1       0     0            0         1           1   \n",
       "oʊ         1       0     0            0         1           1   \n",
       "aʊ         1       0     0            0         1           1   \n",
       "ɹ̩         1       0     0            0         1           1   \n",
       "\n",
       "    delayed release  approximant  tap  trill  ...  strident  lateral  DORSAL  \\\n",
       "ɒ                 0            1    0      0  ...         0        0       1   \n",
       "ɑ                 0            1    0      0  ...         0        0       1   \n",
       "ɶ                 0            1    0      0  ...         0        0       1   \n",
       "a                 0            1    0      0  ...         0        0       1   \n",
       "æ                 0            1    0      0  ...         0        0       1   \n",
       "..              ...          ...  ...    ...  ...       ...      ...     ...   \n",
       "eɪ                0            1    0      0  ...         0        0       1   \n",
       "ɔɪ                0            1    0      0  ...         0        0       1   \n",
       "oʊ                0            1    0      0  ...         0        0       1   \n",
       "aʊ                0            1    0      0  ...         0        0       1   \n",
       "ɹ̩                0            1    0      0  ...         0        0       0   \n",
       "\n",
       "    high  low  front  back  tense  j-offglide  w-offglide  \n",
       "ɒ      0    1      0     1      0           0           0  \n",
       "ɑ      0    1      0     1      0           0           0  \n",
       "ɶ      0    1      1     0      0           0           0  \n",
       "a      0    1      0     0      0           0           0  \n",
       "æ      0    1      1     0      0           0           0  \n",
       "..   ...  ...    ...   ...    ...         ...         ...  \n",
       "eɪ     0    0      1     0      1           1           0  \n",
       "ɔɪ     0    0      0     1      0           1           0  \n",
       "oʊ     0    0      0     1      1           0           1  \n",
       "aʊ     0    1      0     0      0           0           1  \n",
       "ɹ̩     0    0      0     0      0           0           0  \n",
       "\n",
       "[147 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to convert from ARPAbet to IPA\n",
    "\n",
    "arpa_dict = {'AY' : 'aɪ',\n",
    "            'D' : 'd',\n",
    "            'IY' : 'i',\n",
    "            'V' : 'v',\n",
    "            'AE' : 'æ',\n",
    "            'JH' : 'd͡ʒ',\n",
    "            'UH' : 'ʊ',\n",
    "            'T' : 't',\n",
    "            'Y' : 'j',\n",
    "            'AH' : 'ʌ',\n",
    "            'G' : 'ɡ',\n",
    "            'Z' : 'z',\n",
    "            'P' : 'p',\n",
    "            'TH' : 'θ',\n",
    "            'M' : 'm',\n",
    "            'R' : 'ɹ',\n",
    "            'K' : 'k',\n",
    "            'EH' : 'ɛ',\n",
    "            'EY' : 'eɪ',\n",
    "            'NG' : 'ŋ',\n",
    "            'ZH' : 'ʒ',\n",
    "            'HH' : 'h',\n",
    "            'SH' : 'ʃ',\n",
    "            'OY' : 'ɔɪ',\n",
    "            'S' : 's',\n",
    "            'AO' : 'ɔ',\n",
    "            'F' : 'f',\n",
    "            'W' : 'w',\n",
    "            'IH' : 'ɪ',\n",
    "            'DH' : 'ð',\n",
    "            'L' : 'l',\n",
    "            'N' : 'n',\n",
    "            'CH' : 't͡ʃ',\n",
    "            'AA' : 'ɑ',\n",
    "            'B' : 'b',\n",
    "            'OW' : 'oʊ',\n",
    "            'UW' : 'u',\n",
    "            'AW' : 'aʊ',\n",
    "            'ER' : 'ɹ̩'}\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "hayes = pd.read_excel('hayes.xlsx',index_col=0)\n",
    "hayes.replace(r'\\+',1,regex=True,inplace=True)\n",
    "hayes.replace(r'\\-',0,regex=True,inplace=True)\n",
    "hayes.replace(r'0',0,regex=True,inplace=True)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "hayes['j-offglide'] = 0\n",
    "hayes['w-offglide'] = 0\n",
    "\n",
    "for diph in ['aɪ','eɪ','ɔɪ']:\n",
    "    hayes.loc[diph] = hayes.loc[diph[0]]\n",
    "    hayes.loc[diph,'j-offglide'] = 1\n",
    "\n",
    "for diph in ['oʊ','aʊ']:\n",
    "    hayes.loc[diph] = hayes.loc[diph[0]]\n",
    "    hayes.loc[diph,'w-offglide'] = 1\n",
    "\n",
    "# syllabic r\n",
    "hayes.loc['ɹ̩'] = hayes.loc['ɹ']\n",
    "hayes.loc['ɹ̩','syllabic'] = 1\n",
    "\n",
    "print('ok')\n",
    "\n",
    "\n",
    "print(hayes.loc['ɒ'].to_dict())\n",
    "\n",
    "hayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize a bunch of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A20619', 'A69225', 'A20620', 'A36310', 'A43441', 'A03058', 'A80774', 'A34931', 'A64749', 'A64746', 'A64747', 'A95827', 'A89623', 'A52137', 'A64512', 'A80112', 'A64502', 'A52132', 'A52128', 'A52133', 'A58997', 'A57495']\n",
      "\n",
      "22\n",
      "{'tcp_id': 'A20619', 'year': 1611, 'author': 'Donne, John, 1572-1631.', 'title': 'An anatomy of the vvorld Wherein, by occasion of the vntimely death of Mistris Elizabeth Drury the frailty and the decay of this whole world is represented.', 'n_lines': 628}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "metadata = {}\n",
    "for r in pd.read_csv('data/all_catalog_data.csv').to_dict('records'):\n",
    "     metadata[r['tcp_id']] = r\n",
    "        \n",
    "my_corpus_tcp_ids = list(pd.read_csv('data/all_catalog_data.csv')['tcp_id'].to_dict().values())\n",
    "\n",
    "print(my_corpus_tcp_ids)\n",
    "print()\n",
    "print(len(metadata))\n",
    "print(metadata['A20619'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A52137 done 1.4265706539154053\n",
      "A64746 done 15.885968923568726\n",
      "A64502 done 1.5995452404022217\n",
      "A52128 done 0.8525912761688232\n",
      "A64512 done 9.775167226791382\n",
      "A69225 done 66.31577324867249\n",
      "A52133 done 28.854325532913208\n",
      "A80774 done 17.204753637313843\n",
      "A64747 done 17.831329345703125\n",
      "A57495 done 27.573381900787354\n",
      "A20619 done 4.730503559112549\n",
      "A64749 done 19.639446020126343\n",
      "A95827 done 7.525706768035889\n",
      "A34931 done 39.63871121406555\n",
      "A58997 done 6.810512542724609\n",
      "A03058 done 35.353532552719116\n",
      "A80112 done 8.942031383514404\n",
      "A89623 done 3.2040421962738037\n",
      "A36310 done 21.91491460800171\n",
      "A20620 done 9.287647247314453\n",
      "A43441 done 63.109089612960815\n",
      "A52132 done 1.0276663303375244\n",
      "\n",
      "58488\n",
      "\n",
      "{'line_text': ['PAinter', ',', 'once', 'more', 'thy', 'Pencil', 'reassume', '.'], 'line_pos': ['n1', '', 'acp', 'avc-d', 'po', 'n1', 'vvi', ''], 'line_arpabet': ['p/ey/n/t/er', '', 'w/ah/n/s', 'm/ao/r', 'dh/ay', 'p/eh/n/s/ah/l', 'r/iy/ah/s/uw/m', ''], 'line_ipa': ['p/eɪ/n/t/ɹ̩', '', 'w/ʌ/n/s', 'm/ɔ/ɹ', 'ð/aɪ', 'p/ɛ/n/s/ʌ/l', 'ɹ/i/ʌ/s/u/m', ''], 'line_hayes_features': ['001000100000000000000000000000/010010001001010000001000101010/100100100000000000101000000010/100100100000000000000000000000/100010001010000000001000100010', '', '011011001000100000011000001010/010011001000000000001000100010/100100100000000000101000000010/100100101100000000000001000000', '001000100000000000101000000010/011011001000000000011000100010/100010001010000000001000000010', '100100101110000000000000000010/010010001000010001001000100010', '001000100000000000000000000000/010010001001000000001000100010/100100100000000000101000000010/100100101100000000000001000000/010011001000000000001000100010/100110101000000100001000000010', '100010001010000000001000000010/010010001001100000001000101010/010011001000000000001000100010/100100101100000000000001000000/011011001000100000011000101010/001000100000000000101000000010', ''], 'line_v_c': ['C/V/C/C/V', '', 'C/V/C/C', 'C/V/C', 'C/V', 'C/V/C/C/V/C', 'C/V/V/C/V/C', ''], 'n_syllables': 10, 'rhyme_word': 'reassume', 'rhyme_arpabet': 'uw/m', 'rhyme_ipa': 'u/m', 'rhyme_hayes': '011011001000100000011000101010/001000100000000000101000000010', 'tcp_id': 'A52137', 'author': 'Marvell', 'p_number': 0, 'l_number': 0}\n",
      "\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "\n",
      "['CORONAL', 'DORSAL', 'LABIAL', 'anterior', 'approximant', 'back', 'consonantal', 'constr gl', 'continuant', 'delayed release', 'distributed', 'front', 'high', 'j-offglide', 'labiodental', 'lateral', 'long', 'low', 'nasal', 'round', 'sonorant', 'spread gl', 'stress', 'strident', 'syllabic', 'tap', 'tense', 'trill', 'voice', 'w-offglide']\n"
     ]
    }
   ],
   "source": [
    "import glob, json, re, time\n",
    "\n",
    "vectorized_lines = []\n",
    "HAYES_KEYS = ['CORONAL', 'DORSAL', 'LABIAL', 'anterior', 'approximant', 'back', \n",
    "                  'consonantal', 'constr gl', 'continuant', 'delayed release', \n",
    "                  'distributed', 'front', 'high', 'j-offglide', 'labiodental', \n",
    "                  'lateral', 'long', 'low', 'nasal', 'round', 'sonorant', \n",
    "                  'spread gl', 'stress', 'strident', 'syllabic', 'tap', 'tense', \n",
    "                  'trill', 'voice', 'w-offglide']\n",
    "\n",
    "for f in glob.glob('/home/spenteco/0/all_lines_phonemes/*.txt'):\n",
    "    \n",
    "    tcp_id = f.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    if tcp_id not in my_corpus_tcp_ids:\n",
    "        continue\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    text = open(f, 'r', encoding='utf-8').read().replace('<br/>\t<br/>\t<br/>\t<br/>', '')\n",
    "    \n",
    "    paragraphs = text.split('\\n\\n\\n')\n",
    "    \n",
    "    for p_number, p in enumerate(paragraphs):\n",
    "\n",
    "        lines = p.split('\\n\\n')\n",
    "        \n",
    "        for l_number, l in enumerate(lines):\n",
    "            \n",
    "            line_text = []\n",
    "            line_pos = []\n",
    "            line_arpabet = []\n",
    "            line_v_c = []\n",
    "            n_syllables = 0\n",
    "            \n",
    "            tokens = l.split('\\n')\n",
    "            for t in tokens:\n",
    "                \n",
    "                cols = t.split('\\t')\n",
    "                \n",
    "                if len(cols) > 5:\n",
    "\n",
    "                    line_text.append(cols[1])\n",
    "                    line_pos.append(cols[3])\n",
    "                    line_arpabet.append(cols[4])\n",
    "                    line_v_c.append(cols[6])\n",
    "                    n_syllables += len(cols[5].split('/'))\n",
    "                    \n",
    "                elif len(cols) == 4 and cols[3] == '<pc/>':\n",
    "\n",
    "                    line_text.append(cols[1])\n",
    "                    line_pos.append('')\n",
    "                    line_arpabet.append('')\n",
    "                    line_v_c.append('')\n",
    "                    \n",
    "            #if n_syllables == 10:\n",
    "            if True:\n",
    "                \n",
    "                line_vectorizes = True\n",
    "                \n",
    "                line_ipa = []\n",
    "                for w in line_arpabet:\n",
    "                    if w == '':\n",
    "                        line_ipa.append('')\n",
    "                    else:\n",
    "                        w_ipa = []\n",
    "                        for p in re.split('[^a-z]', w):\n",
    "                            if p > '':\n",
    "                                try:\n",
    "                                    w_ipa.append(arpa_dict[p.upper()])\n",
    "                                except KeyError:\n",
    "                                    line_vectorizes = False\n",
    "                                \n",
    "                        line_ipa.append('/'.join(w_ipa))\n",
    "                        \n",
    "                if line_vectorizes:\n",
    "                    \n",
    "                    hayes_feature_counter = {}\n",
    "                    line_hayes_features = []\n",
    "                    \n",
    "                    for w in line_ipa:\n",
    "                        if w.strip() == '':\n",
    "                            line_hayes_features.append('')\n",
    "                        else:\n",
    "\n",
    "                            word_hayes_features = []\n",
    "                            \n",
    "                            for p in w.split('/'):\n",
    "                                try:\n",
    "                                    for feature, onehot in hayes.loc[p].to_dict().items():\n",
    "                                        \n",
    "                                        if feature not in hayes_feature_counter:\n",
    "                                            hayes_feature_counter[feature] = 0\n",
    "                                        hayes_feature_counter[feature] += onehot\n",
    "                                        \n",
    "                                except KeyError:\n",
    "                                    print('KeyError', 'w', w, 'p', p)\n",
    "                                \n",
    "                                word_hayes_features.append([])\n",
    "                                \n",
    "                                temp = hayes.loc[p].to_dict()\n",
    "                                    \n",
    "                                for f in HAYES_KEYS:\n",
    "                                    word_hayes_features[-1].append(str(temp[f]))\n",
    "                                    \n",
    "                                word_hayes_features[-1] = ''.join(word_hayes_features[-1])\n",
    "                                    \n",
    "                            line_hayes_features.append('/'.join(word_hayes_features))\n",
    "                                    \n",
    "                    if len(line_text) == len(line_pos) and \\\n",
    "                        len(line_text) == len(line_arpabet) and \\\n",
    "                        len(line_text) == len(line_ipa) and \\\n",
    "                        len(line_text) == len(line_hayes_features) and \\\n",
    "                        len(line_text) == len(line_v_c):\n",
    "                        pass\n",
    "                    else:\n",
    "                        line_vectorizes = False\n",
    "                    \n",
    "                    if line_vectorizes:\n",
    "                        \n",
    "                        last_a = -1\n",
    "                        last_vc = ''\n",
    "                        \n",
    "                        for a, vc in enumerate(line_v_c):\n",
    "                            if vc.strip() > '':\n",
    "                                last_a = a\n",
    "                                last_vc = vc\n",
    "                                \n",
    "                        last_vc_parts = last_vc.split('/')\n",
    "                        \n",
    "                        last_v_position = -1\n",
    "                        for a, vc in enumerate(last_vc_parts):\n",
    "                            if vc == 'V':\n",
    "                                last_v_position = a\n",
    "                                \n",
    "                        try:\n",
    "                                \n",
    "                            rhyme_arpabet = '/'.join(line_arpabet[last_a].split('/')[last_v_position:])\n",
    "                            rhyme_ipa = '/'.join(line_ipa[last_a].split('/')[last_v_position:])\n",
    "                            rhyme_hayes = '/'.join(line_hayes_features[last_a].split('/')[last_v_position:])\n",
    "                            rhyme_word = line_text[last_a]\n",
    "                        \n",
    "                            vectorized_lines.append({'line_text': line_text,\n",
    "                                                    'line_pos': line_pos,\n",
    "                                                    'line_arpabet': line_arpabet,\n",
    "                                                    'line_ipa': line_ipa,\n",
    "                                                    'line_hayes_features': line_hayes_features,\n",
    "                                                    'line_v_c': line_v_c,\n",
    "                                                    'n_syllables': n_syllables,\n",
    "                                                    'rhyme_word': rhyme_word,\n",
    "                                                    'rhyme_arpabet': rhyme_arpabet,\n",
    "                                                    'rhyme_ipa': rhyme_ipa,\n",
    "                                                    'rhyme_hayes': rhyme_hayes,\n",
    "                                                    'tcp_id': tcp_id,\n",
    "                                                    'author': metadata[tcp_id]['author'].split(',')[0],\n",
    "                                                    'p_number': p_number,\n",
    "                                                    'l_number': l_number})\n",
    "                            \n",
    "                        except:\n",
    "                            #print(line_arpabet)\n",
    "                            #print(line_ipa)\n",
    "                            #print(line_hayes_features)\n",
    "                            pass\n",
    "        \n",
    "    print(tcp_id, 'done', (time.time() - start_time))\n",
    "                \n",
    "print()\n",
    "print(len(vectorized_lines))\n",
    "print()\n",
    "print(vectorized_lines[0])\n",
    "print()\n",
    "print(len(vectorized_lines[0]['line_text']))\n",
    "print(len(vectorized_lines[0]['line_pos']))\n",
    "print(len(vectorized_lines[0]['line_arpabet']))\n",
    "print(len(vectorized_lines[0]['line_ipa']))\n",
    "print(len(vectorized_lines[0]['line_hayes_features']))\n",
    "print(len(vectorized_lines[0]['line_v_c']))\n",
    "\n",
    "print()\n",
    "print(HAYES_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open('data/vectorized_lines.json', 'w', encoding='utf-8')\n",
    "f.write(json.dumps(vectorized_lines, indent=4, ensure_ascii=False))\n",
    "f.close()\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58488\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorized_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
